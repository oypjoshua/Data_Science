{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import cv2 as cv\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train = 'Data/Train'\r\n",
    "test = 'Data/Test'\r\n",
    "validation = 'Data/Validation'\r\n",
    "\r\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0/255, zoom_range=0.1, shear_range=0.2)\r\n",
    "train_datagen = datagen.flow_from_directory(directory=train, target_size=(128,128), batch_size=32, class_mode='binary')\r\n",
    "test_datagen = datagen.flow_from_directory(directory=test, target_size=(128,128), batch_size=32, class_mode='binary')\r\n",
    "validation_datagen = datagen.flow_from_directory(directory=validation, target_size=(128,128), batch_size=32, class_mode='binary')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 10000 images belonging to 2 classes.\n",
      "Found 988 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rescale:\r\n",
    "To normalize the pixel range, which aids in neural network training\r\n",
    "\r\n",
    "Data Augmentation:\r\n",
    "zoom_range:\r\n",
    "how zoomed the image is\r\n",
    "\r\n",
    "shear_range:\r\n",
    "angle augmentation\r\n",
    "\r\n",
    "Batch size vs Epochs:\r\n",
    "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the modelâ€™s internal parameters are updated.\r\n",
    "The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "base_model = tf.keras.applications.densenet.DenseNet201(weights = 'imagenet', input_shape = (128, 128, 3), include_top = False)\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = tf.keras.Sequential()\r\n",
    "model.add(base_model)\r\n",
    "model.add(tf.keras.layers.Flatten())\r\n",
    "model.add(tf.keras.layers.Dense(100, activation = 'relu'))\r\n",
    "# Dropout can be added if necessary to avoid overfitting\r\n",
    "# Dropout is a technique where randomly selected neurons are ignored during training.\r\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\r\n",
    "model.add(tf.keras.layers.Dense(100, activation = 'relu'))\r\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\r\n",
    "model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\r\n",
    "model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Functional)     (None, 4, 4, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30720)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               3072100   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 21,404,285\n",
      "Trainable params: 3,082,301\n",
      "Non-trainable params: 18,321,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(0.001, 10000, 0.00001,power=0.4)\r\n",
    "model.compile(  loss = 'binary_crossentropy',\r\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\r\n",
    "                metrics = ['accuracy'])\r\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\r\n",
    "                                min_delta = 0.005,\r\n",
    "                                patience = 5,\r\n",
    "                                restore_best_weights = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "history = model.fit(train_datagen,\r\n",
    "                    validation_data = validation_datagen,\r\n",
    "                    epochs = 40,\r\n",
    "                    callbacks = [callback],\r\n",
    "                    verbose = 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n",
      "313/313 [==============================] - 562s 2s/step - loss: 0.0651 - accuracy: 0.9898 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
      "Epoch 2/40\n",
      "313/313 [==============================] - 588s 2s/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.0446 - val_accuracy: 0.9912\n",
      "Epoch 3/40\n",
      "313/313 [==============================] - 560s 2s/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0362 - val_accuracy: 0.9962\n",
      "Epoch 4/40\n",
      "313/313 [==============================] - 560s 2s/step - loss: 0.0141 - accuracy: 0.9970 - val_loss: 2.0016e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/40\n",
      "313/313 [==============================] - 545s 2s/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 5.8576e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/40\n",
      "313/313 [==============================] - 530s 2s/step - loss: 2.3646e-04 - accuracy: 0.9999 - val_loss: 0.0110 - val_accuracy: 0.9975\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.evaluate(test_datagen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "31/31 [==============================] - 54s 2s/step - loss: 0.0393 - accuracy: 0.9949\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0392596572637558, 0.9949392676353455]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "tzuyu = plt.imread('tzuyu.jpg')\r\n",
    "tzuyu_mask = plt.imread('tzuyu_mask.jpg')\r\n",
    "# imagedatagenerator/plt.imshow uses RGB\r\n",
    "# OpenCV uses BGR\r\n",
    "tzuyu = cv.resize(tzuyu, (128,128), interpolation = cv.INTER_CUBIC)\r\n",
    "tzuyu_mask = cv.resize(tzuyu_mask, (128,128), interpolation = cv.INTER_CUBIC)\r\n",
    "ty_predict = np.array(tzuyu / 255)\r\n",
    "ty_mask_predict = np.array(tzuyu_mask / 255)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model.predict(np.array([ty_predict]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.predict(np.array([ty_mask_predict]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[9.129589e-16]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "model.save('mask_detection_128x128.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "8fbb0947df70a354583935f9584a4b89d4a7adfa2a8c6e56802a6980c3b97cf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}